{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Image Classification with Keras\n",
    "\n",
    "The homework consists of two parts: theoretical part (7 pts) and coding part (16.5+10 pts).\n",
    " - All theoretical questions must be answered in your own words, do not copy-paste text from the internet. Points can be deducted for terrible formatting or incomprehensible English.\n",
    " - Code must be commented. If you use code you found online, you have to add the link to the source you used. There is no penalty for using outside sources as long as you convince us you understand the code.\n",
    "\n",
    "**Note that coding part consists of two different notebooks.**\n",
    "\n",
    "*Once completed zip the entire directory containing this exercise and upload it to https://courses.cs.ut.ee/2020/nn/spring/Main/Practices.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you did this homework together with course mates, please write here their names (answers still have to be your own!).**\n",
    "\n",
    "**Name(s):** fill this in if applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Theory Exercises\n",
    "\n",
    "These theoretical questions are about the material covered in the lecture about \"Recurrent Neural Networks\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.1 (7pts):** Recurrent networks: basic truths and architectures\n",
    "\n",
    "Which of the following is true about recurrent neural networks. In case of ”True” bring\n",
    "an example (e.g. suffices to refer to a slide in lecture), in case of ”False”, explain.\n",
    "\n",
    "1. A recurrent network always produces one output prediction per timestep.\n",
    "2. It is possible to put a convolutional layer between the input and the recurrent layer.\n",
    "3. The final layer (that makes the classification/regression) must be connected directly to the recurrent layer.\n",
    "4. In all RNNs types seen in the lecture, output produced at timestep t can only depend on inputs received at timesteps 0 to t, and not on future timesteps.\n",
    "5. All layers of a recurrent neural network are recurrent.\n",
    "6. Only one layer of the recurrent network can be recurrent (two recurrent layers would make no sense).\n",
    "7. The activations of the hidden nodes stay the same across all timesteps.\n",
    "8. Different timesteps use the exact same weight matrices only in recurrent layers. This does not apply to other layers.\n",
    "9. Different timesteps use the exact same weight matrices. This applies to all layers.\n",
    "10. Gradient clipping is important to battle against gradients getting weaker and weaker.\n",
    "11. LSTM networks deal with long term dependencies better than simple RNNs, because they have less parameters.\n",
    "12. The gates in LSTM are opened or closed depending on the current input and current hidden state and it does not matter which timestep it currently is.\n",
    "13. I have trained my network to predict the weather on the 8th day based on the weather of previous 7 days. I now have weather from only past 5 days available. I can still use the same network to predict weather tomorrow (accuracy might be bad, but we can use fewer inputs without changing the network).\n",
    "14. I can train a recurrent network to receive input only at the first timestep and then produce arbitrarily long sequence of outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises\n",
    "\n",
    "You've written a lot of code in this course to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "For the last part of the course, though, we're going to leave behind your beautiful codebase and instead migrate to a popular deep learning framework: [Keras](https://keras.io/). Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. Keras has very well designed API, which allows for concise code and flexibility at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "#### Linux\n",
    "\n",
    "To install Keras enter following on Conda command-line:\n",
    "```\n",
    "conda install keras\n",
    "```\n",
    "\n",
    "By default Keras uses Tensorflow backend. If you happen to have recent NVidia GPU on your machine, you might want to install GPU version of Tensorflow:\n",
    "```\n",
    "conda install tensorflow-gpu\n",
    "```\n",
    "When you import Keras in your code, you should see \"Using TensorFlow backend.\" notice.\n",
    "\n",
    "PS. If you have non-NVidia GPU, you might want to give a shot to [PlaidML](http://vertex.ai/blog/announcing-plaidml) Keras backend.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "To install Keras enter following on Conda command-line:\n",
    "```\n",
    "pip install keras\n",
    "```\n",
    "By default Keras uses Tensorflow backend. If you happen to have recent NVidia GPU on your machine, you might want to install GPU version of Tensorflow:\n",
    "```\n",
    "pip install tensorflow-gpu\n",
    "```\n",
    "When you import Keras in your code, you should see \"Using TensorFlow backend.\" notice.\n",
    "\n",
    "#### In case you face some problems\n",
    "If you see an error about tensorflow or that \"Softmax does not have axis argument\", run the following line:\n",
    "```\n",
    "pip install tensorflow==1.12.0\n",
    "```\n",
    "\n",
    "If you get an error with Numpy, make sure you have the last version by running:\n",
    "```\n",
    "pip intall -U numpy\n",
    "```\n",
    "\n",
    "When working with the notebook `Network.ipynb`, if you have a problem importing `from keras.applications.imagenet_utils import CLASS_INDEX`, then you can use `keras_applications`:\n",
    "```\n",
    "pip install keras_applications==1.0.7\n",
    "```\n",
    "and tehn replace the line\n",
    "```\n",
    "from keras.applications.imagenet_utils import CLASS_INDEX\n",
    "```\n",
    "with\n",
    "```\n",
    "from keras_applications.imagenet_utils import CLASS_INDEX\n",
    "```\n",
    "\n",
    "**Note:** if with all this you are still in trouble, you can create a new environment with the `requirements.txt` file. This file contains the required packages and has been tested with this notebook.\n",
    "```\n",
    "conda create  python=3.6 --name neural_networks_env\n",
    "source activate neural_networks_env\n",
    "conda install --file practice6/requirements.txt\n",
    "```\n",
    "then make sure that the kernel you use in jupyer is neural_networks_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Keras includes builtin support for datasets like MNIST, CIFAR, etc.\n",
    "The first time you load a dataset it might take some time to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# Keras comes with built-in loaders for common datasets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# shorten dataset for quicker training\n",
    "# feel free to comment those out if you have GPU\n",
    "X_train = X_train[:25000]\n",
    "y_train = y_train[:25000]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model\n",
    "\n",
    "Keras has two options for creating models: [sequential](https://keras.io/getting-started/sequential-model-guide/) and [functional API](https://keras.io/getting-started/functional-api-guide/). We are going to use functional API, because it matches well with computational graph model what neural networks really are. Also functional API allows branching, layer sharing and other advanced features we might need later.\n",
    "\n",
    "Study the following code and see how we first create input tensor `x`, then apply layers to intermediate tensors until we produce tensor of probabilities `p`. Layers are implemented as [functors](https://www.daniweb.com/programming/software-development/threads/485098/functors-in-python) in Keras, meaning they are objects that can be called as functions. You can print out intermediate tensors `h` to see their shapes. Remember, here we just define the computational graph, no calculations are made yet. For more information see Keras documentation:\n",
    " - [Core layers](https://keras.io/layers/core/)\n",
    " - [Convolutional layers](https://keras.io/layers/convolutional/)\n",
    " - [Activations](https://keras.io/activations/)\n",
    "\n",
    "Then the model is created with `x` as input and `p` as output. Cross-entropy loss is applied to the network with Adam optimizer and additional accuracy metric. `sparse_categorical_crossentropy` loss allows us to pass integer class values directly as targets and is potentially more efficient than `categorical_crossentropy`, which needs one-hot vectors as targets. For more information see Keras documentation:\n",
    " - [Losses](https://keras.io/losses/)\n",
    " - [Optimizers](https://keras.io/optimizers/)\n",
    " - [Metrics](https://keras.io/metrics/)\n",
    "\n",
    "`model.summary()` prints out layer list with output shapes and is very useful for debugging the model. Also it shows number of trainable parameters, which is useful metric to estimate the capacity of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "x = Input(shape=(32, 32, 3))\n",
    "h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "h = Activation('relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(10)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "# Now that we have defined how to find p from x, we can create a \n",
    "# model simply by saying what is input and what is output\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.1 (1pt):** Why accuracy cannot be used as a loss function?\n",
    "\n",
    "**Your answer:** *fill this in*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First training\n",
    "\n",
    "Now we train our first model in Keras. Keras follows simple style similar to Scikit-learn, where a model has methods `fit()`, `predict()` and `evaluate()`. Notice how we use `validation_split` parameter to automatically produce validation set that is 4% of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=5, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`History` object returned by `model.fit()` can be used to plot learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.2 (1pt):** Why training set accuracy is lower than validation set accuracy in the first epochs? Hint: training accuracy is an average over all training batches in epoch. When is validation accuracy calculated?\n",
    "\n",
    "**Your answer:** *fill this in*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use model `predict()` method to produce predictions on given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "print(\"Test set accuracy:\", np.mean(y_pred == y_test[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we just want to evaluate the metrics and losses, it's easier to use `evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IPython notebook just prints out the returned values - loss and accuracy\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the same for training set\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "The above results were not very impressive. What are we missing? It turns out neural networks work much better with normalized inputs, which are around 0 (the most effective region of activation function).\n",
    "\n",
    "We are going to try out three different normalization methods:\n",
    " - **centering** (subtracting the mean),\n",
    " - **standardization** (subtract mean and divide by standard deviation),\n",
    " - **minmax** (subtract min and divide by max-min).\n",
    "\n",
    "For images it is sufficient to calculate statistcs for each color channel, e.g. you take mean over entire training set and also over all pixel positions. NB! The statistics (mean, standard deviation, min/max) must be always calculated on training set and the same values must be applied to validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.3 (3pts):** try different methods to normalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Normalize pixel values by centering (subtract mean of each channel). #\n",
    "##############################################################################\n",
    "X_train_mean = None\n",
    "X_test_mean = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "# redefine the layers to reinitialize weights\n",
    "x = Input(shape=(32, 32, 3))\n",
    "h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "h = Activation('relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(10)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "history = model.fit(X_train_mean, y_train, batch_size=64, epochs=5, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Normalize pixel values by subtracting mean and dividing by standard  #\n",
    "# deviation (for each channel).                                              #\n",
    "##############################################################################\n",
    "X_train_meanstd = None\n",
    "X_test_meanstd = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "# redefine the layers to reinitialize weights\n",
    "x = Input(shape=(32, 32, 3))\n",
    "h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "h = Activation('relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(10)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "history = model.fit(X_train_meanstd, y_train, batch_size=64, epochs=5, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Normalize pixel values by scaling them between 0 and 1. (MinMax)     #\n",
    "##############################################################################\n",
    "X_train_minmax = None\n",
    "X_test_minmax = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "# redefine the layers to reinitialize weights\n",
    "x = Input(shape=(32, 32, 3))\n",
    "h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "h = Activation('relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(10)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n",
    "history = model.fit(X_train_minmax, y_train, batch_size=64, epochs=5, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.4 (1pt):** which normalization worked the best? What do you think why?\n",
    "\n",
    "**Your answer:** *fill this in*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Assign the best data to X_train_norm and X_test_norm variables.      #\n",
    "##############################################################################\n",
    "X_train_norm = None\n",
    "X_test_norm = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More elaborate network\n",
    "\n",
    "Create a network with following layers:\n",
    "1. 3x3 convolution with 32 filters, stride 1, padding same\n",
    "2. batch normalization\n",
    "3. relu\n",
    "4. 3x3 convolution with 32 filters, stride 1, padding valid\n",
    "5. batch normalization\n",
    "6. relu\n",
    "7. max pooling 2x2\n",
    "8. dropout 0.25\n",
    "7. flatten\n",
    "8. dense 100\n",
    "5. batch normalization\n",
    "6. relu\n",
    "8. dropout 0.5\n",
    "8. dense 10\n",
    "9. softmax\n",
    "\n",
    "You can consult Keras documentation for layer parameters:\n",
    " - [Convolutional layers](https://keras.io/layers/convolutional/)\n",
    " - [Pooling layers](https://keras.io/layers/pooling/)\n",
    " - [Normalization layers](https://keras.io/layers/normalization/)\n",
    "\n",
    "Use the best data normalization from the previous step! You should get validation accuracy above 65%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5 (1pt):** understanding padding\n",
    "\n",
    "What is the difference between \"padding same\" and \"padding valid\"?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.6 (0.5pt):** understanding dropout\n",
    "\n",
    "In Keras, is the dropout probability interpreted as probability of keeping each node or probability of dropping?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.7 (6pts):** create a network with given layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, BatchNormalization, Dropout\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Create a network with given layers. Please keep the tensor naming,   #\n",
    "#       we will need it later.                                               #\n",
    "##############################################################################\n",
    "x = None\n",
    "c1 = None\n",
    "b1 = None\n",
    "a1 = None\n",
    "c2 = None\n",
    "b2 = None\n",
    "a2 = None\n",
    "p2 = None\n",
    "d2 = None\n",
    "f2 = None\n",
    "h3 = None\n",
    "b3 = None\n",
    "a3 = None\n",
    "d3 = None\n",
    "z = None\n",
    "p = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# feel free to use more epochs if you have GPU\n",
    "history = model.fit(X_train_norm, y_train, batch_size=64, epochs=5, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Model trained for classification can be used in other creative ways, for example finding similar images. The hidden layer activations can be thought of as features extracted from the images. As the final goal is to classifiy images into categories, we can assume that in the last layers the features of semantically similar images are similar. That means they are close to each other according to Euclidean distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When choosing which layer features to use `Dense(100)` layer seems like a good pick - it is positioned late in the network (close to output), meaning the features should reflect the semantic meaning relatively well. Also, it has sensible dimensions - 100. We create a new model that outputs not the classification, but the `Dense(100)` layer features. We can now use `predict()` to produce features of the entire test set.\n",
    "\n",
    "Notice we are using the activation value before dropout and before relu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# outputs are the features from Dense(100) layer of the previously trained model\n",
    "# because we do not redefine the layers, weights remain the same\n",
    "extract_model = Model(inputs=x, outputs=h3)\n",
    "features = extract_model.predict(X_test_norm)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.8 (1pt):** calculate euclidean distance matrix between test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Calculate euclidean distance matrix between test set images.         #\n",
    "# You can either use code from the first homework or scipy.                  #\n",
    "##############################################################################\n",
    "dists = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take first 10 images from the test set and plot their 9 most similar images from the same set, along with distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(10):\n",
    "    closest = np.argsort(dists[i])[:10]\n",
    "    for k, j in enumerate(closest):\n",
    "        plt.subplot(10, 10, i*10 + k + 1)\n",
    "        plt.imshow(X_test[j])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"d=%0.2f\" % dists[i, j])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.9 (2pts):** Describe the results. Describe the mistakes it makes. A nearest-neighbour search on the input images would simply return images with most similar pixel values, how are these results different?  \n",
    "\n",
    "**Your answer:** *fill this in*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
